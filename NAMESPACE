# Generated by roxygen2: do not edit by hand

S3method(tokenize,BasicTokenizer)
S3method(tokenize,FullTokenizer)
S3method(tokenize,WordpieceTokenizer)
export(BasicTokenizer)
export(FullTokenizer)
export(WordpieceTokenizer)
export(check_vocab)
export(convert_by_vocab)
export(convert_ids_to_tokens)
export(convert_to_unicode)
export(convert_tokens_to_ids)
export(custom_layer_BERT)
export(custom_layer_attention)
export(custom_layer_bert_embeddings)
export(custom_layer_layernorm)
export(custom_layer_position_embedding)
export(custom_layer_proj_add_norm)
export(custom_layer_transformer_encoder)
export(custom_layer_transformer_encoder_single)
export(download_BERT_checkpoint)
export(find_ckpt)
export(find_config)
export(find_vocab)
export(gelu)
export(get_activation)
export(get_params_from_checkpoint)
export(get_shape_list)
export(load_bert_model)
export(load_vocab)
export(run_bert_model_on_text)
export(set_BERT_dir)
export(text_to_id)
export(tokenize)
export(tokenize_text)
export(tokenize_word)
export(whitespace_tokenize)

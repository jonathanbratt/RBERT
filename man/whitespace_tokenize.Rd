% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenization.R
\name{whitespace_tokenize}
\alias{whitespace_tokenize}
\title{Run basic whitespace cleaning and splitting on a piece of text.}
\usage{
whitespace_tokenize(text)
}
\arguments{
\item{text}{Character scalar to tokenize.}
}
\value{
Character vector of tokens.
}
\description{
Run basic whitespace cleaning and splitting on a piece of text.
}
\examples{
whitespace_tokenize(text = " some\ttext \n with  whitespace ")
}

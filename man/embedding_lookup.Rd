% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/modeling.R
\name{embedding_lookup}
\alias{embedding_lookup}
\title{Look up words embeddings for id tensor}
\usage{
embedding_lookup(input_ids, vocab_size, embedding_size = 128L,
  initializer_range = 0.02, word_embedding_name = "word_embeddings",
  use_one_hot_embeddings = FALSE)
}
\arguments{
\item{input_ids}{Integer Tensor of shape [batch_size, seq_length] containing
word ids.}

\item{vocab_size}{Size of the embedding vocabulary (integer).}

\item{embedding_size}{Width of the word embeddings (integer).}

\item{initializer_range}{Embedding initialization range (float).}

\item{word_embedding_name}{Name of the embedding table (character).}

\item{use_one_hot_embeddings}{If TRUE, use one-hot method for word
embeddings. If FALSE, use \code{tf$gather()}.}
}
\value{
Float Tensor of shape [batch_size, seq_length, embedding_size], along
  with the embedding table in a list.
}
\description{
Look up words embeddings for id tensor
}
\examples{
\dontrun{
with(tensorflow::tf$variable_scope("examples",
                                   reuse = tensorflow::tf$AUTO_REUSE),
     ids <- tensorflow::tf$get_variable("x", dtype = "int32",
                                        shape = tensorflow::shape(10, 20))
)
embedding_lookup(ids, vocab_size = 100, word_embedding_name = "some_name")

}
}

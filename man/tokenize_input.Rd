% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenization.R
\name{tokenize_input}
\alias{tokenize_input}
\title{Tokenize Text for Input to BERT}
\usage{
tokenize_input(
  seq_list,
  vocab,
  pad_to_length = NULL,
  sep_token = "[SEP]",
  cls_token = "[CLS]",
  pad_token = "[PAD]"
)
}
\arguments{
\item{seq_list}{Character vector or list; text to tokenize.}

\item{vocab}{A wordpiece vocabulary.}

\item{pad_to_length}{Integer; optional length to pad sequences to.}

\item{sep_token}{Character; token to use at end of each segment. Should exist
in \code{vocab}.}

\item{cls_token}{Character; token to use at start of sequence. Should exist
in \code{vocab}.}

\item{pad_token}{Character; token to use for padding sequence. Should exist
in \code{vocab}.}
}
\value{
The tokenized output as a named integer vector, with token type ids
  attached as an attribute.
}
\description{
Given a list of text sequences and a wordpiece vocabulary, tokenize the input
sequences into a form suitable for use with RBERT. If the input is a flat
list or character vector, the sequences will be single-segment. If the input
contains length-2 sublists or vectors, those examples will be two-segment
sequences, e.g. for doing sentence-pair classification.
}
\details{
The token type ids (0 for first segment, 1 for second) are attached as an
attribute.
}
\examples{
vocab_path <- system.file("extdata", "tiny_vocab.txt", package = "wordpiece")
vocab <- wordpiece::load_vocab(vocab_file = vocab_path)
tokenize_input(c(
  "Here are some words.",
  "Here are some more words."
),
vocab)
tokenize_input(list(
  c(
    "First sequence, first segment.",
    "First sequence, second segment."
  ),
  c(
    "Second sequence, first segment.",
    "Second sequence, second segment."
  )
),
vocab)
}

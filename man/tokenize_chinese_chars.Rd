% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenization.R
\name{tokenize_chinese_chars}
\alias{tokenize_chinese_chars}
\title{Add whitespace around any CJK character.}
\usage{
tokenize_chinese_chars(text)
}
\arguments{
\item{text}{A character scalar.}
}
\value{
Text with spaces around CJK characters.
}
\description{
(R implementation of BasicTokenizer._tokenize_chinese_chars from
BERT: tokenization.py.) This may result in doubled-up spaces,
but that's the behavior of the python code...
}
\keyword{internal}

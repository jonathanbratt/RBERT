% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenization.R
\name{split_on_punc}
\alias{split_on_punc}
\title{Split text on punctuation.}
\usage{
split_on_punc(text)
}
\arguments{
\item{text}{A character scalar, encoded as utf-8.}
}
\value{
The input text as a character vector, split on punctuation
characters.
}
\description{
(R implementation of BasicTokenizer._run_split_on_punc from
BERT: tokenization.py.)
}
\keyword{internal}

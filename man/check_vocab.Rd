% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenization.R
\name{check_vocab}
\alias{check_vocab}
\title{Check Vocabulary}
\usage{
check_vocab(words, ckpt_dir = NULL, vocab_file = find_vocab(ckpt_dir))
}
\arguments{
\item{words}{Character vector; words to check.}

\item{ckpt_dir}{Character; path to checkpoint directory. If specified, any
other checkpoint files required by this function (\code{vocab_file},
\code{bert_config_file}, or \code{init_checkpoint}) will default to
standard filenames within \code{ckpt_dir}.}

\item{vocab_file}{path to vocabulary file. File is assumed to be a text file,
with one token per line, with the line number corresponding to the index of
that token in the vocabulary.}
}
\value{
A logical vector containing \code{TRUE} if the corresponding word was
  found verbatim in the vocabulary, \code{FALSE} otherwise.
}
\description{
Given some words and a word piece vocabulary, checks to see if the words are
in the vocabulary.
}
\examples{
\dontrun{
BERT_PRETRAINED_DIR <- download_BERT_checkpoint("bert_base_uncased")
to_check <- c("apple", "appl")
check_vocab(words = to_check, ckpt_dir = BERT_PRETRAINED_DIR) # TRUE, FALSE
#' }
}
